{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10_cnn_004.ipynb","provenance":[],"mount_file_id":"1Dzmfk4OpYo6ax5KhEglYn0qUCuKU5GpK","authorship_tag":"ABX9TyMtMwiV4qx9rvIOMdV0tfHG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gVcTGSCBtnga","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609739529419,"user_tz":-540,"elapsed":662,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"a6547df2-b8d4-48d8-ce0d-6fa1faa4ef8b"},"source":["%cd /content/drive/MyDrive/Cifar10"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Cifar10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZ5CLVReGOux"},"source":["import torch\r\n","import torch.nn.functional as f\r\n","from torch.utils.data import DataLoader\r\n","from torchvision import datasets, transforms\r\n","import matplotlib.pyplot as plt\r\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2NILNFXjGUOg"},"source":["ネットワークモデル"]},{"cell_type":"code","metadata":{"id":"SZU4EBmBfhol"},"source":["class MyCNN(torch.nn.Module):\r\n","    def __init__(self):\r\n","        super(MyCNN, self).__init__()\r\n","        self.conv1 = torch.nn.Conv2d(3,  # チャネル入力\r\n","                                     6,  # チャンネル出力\r\n","                                     5,  # カーネルサイズ\r\n","                                     1,  # ストライド (デフォルトは1)\r\n","                                     0,  # パディング (デフォルトは0)\r\n","                                     )\r\n","        self.conv2 = torch.nn.Conv2d(6, 16, 5)\r\n"," \r\n","        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\r\n"," \r\n","        self.dropout1 = torch.nn.Dropout2d(p=0.3)  # [new] Dropoutを追加してみる\r\n"," \r\n","        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)  # 入力サイズ, 出力サイズ\r\n","        self.dropout2 = torch.nn.Dropout(p=0.5)  # [new] Dropoutを追加してみる\r\n","        self.fc2 = torch.nn.Linear(120, 84)\r\n","        self.fc3 = torch.nn.Linear(84, 10)\r\n"," \r\n","    def forward(self, x):\r\n","        x = f.relu(self.conv1(x))\r\n","        x = self.pool(x)\r\n","        x = f.relu(self.conv2(x))\r\n","        x = self.pool(x)\r\n","        x = self.dropout1(x)  # [new] Dropoutを追加\r\n","        x = x.view(-1, 16 * 5 * 5)  # 1次元データに変えて全結合層へ\r\n","        x = f.relu(self.fc1(x))\r\n","        x = self.dropout2(x)   # [new] Dropoutを追加\r\n","        x = f.relu(self.fc2(x))\r\n","        x = self.fc3(x)\r\n"," \r\n","        return x\r\n"," \r\n","    # 畳み込みカーネルの表示\r\n","    def plot_conv1(self, prefix_num=0):\r\n","        weights1 = self.conv1.weight\r\n","        weights1 = weights1.reshape(3*6, 5, 5)\r\n"," \r\n","        for i, weight in enumerate(weights1):\r\n","            plt.subplot(3, 6, i + 1)\r\n","            plt.imshow(weight.data.to('cpu').numpy(), cmap='winter')\r\n","            plt.tick_params(labelbottom=False,\r\n","                            labelleft=False,\r\n","                            labelright=False,\r\n","                            labeltop=False,\r\n","                            bottom=False,\r\n","                            left=False,\r\n","                            right=False,\r\n","                            top=False)\r\n"," \r\n","        plt.savefig('img/{}_conv1.png'.format(prefix_num))\r\n","        plt.close()\r\n"," \r\n","    def plot_conv2(self, prefix_num=0):\r\n","        weights2 = self.conv2.weight\r\n","        weights2 = weights2.reshape(6*16, 5, 5)\r\n"," \r\n","        for i, weight in enumerate(weights2):\r\n","            plt.subplot(6, 16, i + 1)\r\n","            plt.imshow(weight.data.to('cpu').numpy(), cmap='winter')\r\n","            plt.tick_params(labelbottom=False,\r\n","                            labelleft=False,\r\n","                            labelright=False,\r\n","                            labeltop=False,\r\n","                            bottom=False,\r\n","                            left=False,\r\n","                            right=False,\r\n","                            top=False)\r\n"," \r\n","        plt.savefig('img/{}_conv2.png'.format(prefix_num))\r\n","        plt.close()\r\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8VWPt-XAkMo"},"source":["データローダー"]},{"cell_type":"code","metadata":{"id":"5F9aYAZ2Acaa"},"source":["def load_cifar10(batch=128):\r\n","    train_loader = DataLoader(\r\n","        datasets.CIFAR10('./data',\r\n","                         train=True,\r\n","                         download=True,\r\n","                         transform=transforms.Compose([\r\n","                             transforms.ToTensor(),\r\n","                             transforms.Normalize(\r\n","                                [0.5, 0.5, 0.5],  # RGB 平均\r\n","                                [0.5, 0.5, 0.5]   # RGB 標準偏差\r\n","                                )\r\n","                         ])),\r\n","        batch_size=batch,\r\n","        shuffle=True\r\n","    )\r\n"," \r\n","    test_loader = DataLoader(\r\n","        datasets.CIFAR10('./data',\r\n","                         train=False,\r\n","                         download=True,\r\n","                         transform=transforms.Compose([\r\n","                             transforms.ToTensor(),\r\n","                             transforms.Normalize(\r\n","                                 [0.5, 0.5, 0.5],  # RGB 平均\r\n","                                 [0.5, 0.5, 0.5]  # RGB 標準偏差\r\n","                             )\r\n","                         ])),\r\n","        batch_size=batch,\r\n","        shuffle=True\r\n","    )\r\n"," \r\n","    return {'train': train_loader, 'test': test_loader}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohbOn92H9aso"},"source":["学習とテストの実行"]},{"cell_type":"code","metadata":{"id":"iMYtFujy9Mm4"},"source":[" #=====================================================================\r\n","if __name__ == '__main__':\r\n","    epoch = 300\r\n"," \r\n","    loader = load_cifar10()\r\n","    classes = ('plane', 'car', 'bird', 'cat', 'deer',\r\n","               'dog', 'frog', 'horse', 'ship', 'truck')\r\n"," \r\n","    net: MyCNN = MyCNN()\r\n","    criterion = torch.nn.CrossEntropyLoss()  # ロスの計算\r\n","    optimizer = torch.optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\r\n"," \r\n","    # もしGPUが使えるなら使う\r\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n","    net.to(device)\r\n","    print(device)\r\n"," \r\n","    # 学習前のフィルタの可視化\r\n","    net.plot_conv1()\r\n","    net.plot_conv2()\r\n"," \r\n","    history = {\r\n","        'train_loss': [],\r\n","        'train_acc': [],\r\n","        'test_acc': []\r\n","    }\r\n"," \r\n","    for e in range(epoch):\r\n","        net.train()\r\n","        loss = None\r\n","        for i, (images, labels) in enumerate(loader['train']):\r\n","            images = images.to(device)  # to GPU?\r\n","            labels = labels.to(device)\r\n"," \r\n","            optimizer.zero_grad()\r\n","            output = net(images)\r\n","            loss = criterion(output, labels)\r\n","            loss.backward()\r\n","            optimizer.step()\r\n"," \r\n","            if i % 10 == 0:\r\n","                print('Training log: {} epoch ({} / 50000 train. data). Loss: {}'.format(e + 1,\r\n","                                                                                         (i + 1) * 128,\r\n","                                                                                         loss.item())\r\n","                      )\r\n"," \r\n","        # 学習過程でのフィルタの可視化\r\n","        # net.plot_conv1(e+1)\r\n","        # net.plot_conv2(e+1)\r\n"," \r\n","        history['train_loss'].append(loss.item())\r\n"," \r\n","        net.eval()\r\n","        correct = 0\r\n","        with torch.no_grad():\r\n","            for i, (images, labels) in enumerate(tqdm(loader['train'])):\r\n","                images = images.to(device)  # to GPU?\r\n","                labels = labels.to(device)\r\n"," \r\n","                outputs = net(images)\r\n","                _, predicted = torch.max(outputs.data, 1)\r\n","                correct += (predicted == labels).sum().item()\r\n"," \r\n","        acc = float(correct / 50000)\r\n","        history['train_acc'].append(acc)\r\n"," \r\n","        correct = 0\r\n","        with torch.no_grad():\r\n","            for i, (images, labels) in enumerate(tqdm(loader['test'])):\r\n","                images = images.to(device)  # to GPU?\r\n","                labels = labels.to(device)\r\n"," \r\n","                outputs = net(images)\r\n","                _, predicted = torch.max(outputs.data, 1)\r\n","                correct += (predicted == labels).sum().item()\r\n"," \r\n","        acc = float(correct / 10000)\r\n","        history['test_acc'].append(acc)\r\n"," \r\n","\r\n","        print(\"Accuracy : %f\" % acc)\r\n","\r\n","    # 学習前のフィルタの可視化\r\n","    net.plot_conv1(300)\r\n","    net.plot_conv2(300)\r\n"," \r\n","    # 結果をプロット\r\n","    plt.plot(range(1, epoch+1), history['train_loss'])\r\n","    plt.title('Training Loss [CIFAR10]')\r\n","    plt.xlabel('epoch')\r\n","    plt.ylabel('loss')\r\n","    plt.savefig('img/cifar10_loss.png')\r\n","    plt.close()\r\n"," \r\n","    plt.plot(range(1, epoch + 1), history['train_acc'], label='train_acc')\r\n","    plt.plot(range(1, epoch + 1), history['test_acc'], label='test_acc')\r\n","    plt.title('Accuracies [CIFAR10]')\r\n","    plt.xlabel('epoch')\r\n","    plt.ylabel('accuracy')\r\n","    plt.legend()\r\n","    plt.savefig('img/cifar10_acc.png')\r\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUxLyZmD9MOi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qhZhb0ar4Lu","executionInfo":{"status":"ok","timestamp":1609686569990,"user_tz":-540,"elapsed":709,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"14461c30-8594-4054-e1af-191a8e2a6b50"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ef4Nb2uwr5ob","executionInfo":{"status":"ok","timestamp":1609685751758,"user_tz":-540,"elapsed":626,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"1aa1a4c8-bd34-4268-ac23-11cff0389137"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cifar10_cnn_003.ipynb  data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ne5JkmXar_-T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6_vfPr999Hp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2k9UeHCsNrp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LnsXCMP9_94","executionInfo":{"status":"ok","timestamp":1609739902127,"user_tz":-540,"elapsed":670,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}}},"source":["import numpy as np"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b654MtTI9_5_","executionInfo":{"status":"ok","timestamp":1609739904134,"user_tz":-540,"elapsed":637,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"9ae3caec-0f7b-460f-d7cb-1e65c8f8b31c"},"source":["a=np.array([1])\r\n","print(a)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nd-aDNVt9_1Q","executionInfo":{"status":"ok","timestamp":1609739909934,"user_tz":-540,"elapsed":645,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"652954b7-7160-45c1-8573-6a1706c365d2"},"source":["b=a\r\n","print(b)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WN-u9vMm9_lP","executionInfo":{"status":"ok","timestamp":1609739918161,"user_tz":-540,"elapsed":584,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"a5a5b15f-46bc-4f7c-d7d0-4ba9f9f10ba2"},"source":["b=[2]\r\n","print(b)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oJljoN5-LyG","executionInfo":{"status":"ok","timestamp":1609739918967,"user_tz":-540,"elapsed":629,"user":{"displayName":"Hioryuki Onishi","photoUrl":"","userId":"17098326242855842755"}},"outputId":"e1d4ab97-5cc9-471f-89de-f6acc228da6d"},"source":["print(a,b)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[1] [2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oSf2Xroz-Nx6"},"source":[""],"execution_count":null,"outputs":[]}]}